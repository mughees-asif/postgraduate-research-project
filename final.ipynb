{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:blue'><center>Recommendation System using Graph Neural Networks</center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "<b style='color:DodgerBlue'><center><a href='https://www.linkedin.com/in/mugheesasif/'>Mughees Asif</a></center></b>\n",
    "<b style='color:DodgerBlue'><center><a href='https://www.sems.qmul.ac.uk/staff/a.nanjangud'>Dr Angadh Nanjangud</a></center></b>\n",
    "<i style='color:rgb(0, 122, 172)'><center><a href='http://www.eecs.qmul.ac.uk/'>School of Electronic Engineering and Computer Science</a></center></i>\n",
    "<i style='color:rgb(0, 122, 172)'><center><a href='https://www.qmul.ac.uk/'>Queen Mary, University of London</a></center></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Recently, neural networks have been used in developing recommendation systems that can parse graph-like data structures to develop meaningful representations from user-to-item relationships and social network information. Moreover, recommendation systems that have been developed with Graph Neural Networks (GNNs) expedite the aggregation process of macro (e.g., topological structure) and micro (e.g., node information) operations, and therefore enhance the overall information filtering capabilities of the system. However, the representation learning process is non-linear as social relationships combined with item interactions, both, need to be considered for optimal results. This research project aimed to address this by proposing a recommendation system that is capable of using the underlying social connections between users and items. The system was also split into three variations where several metrics were used to draw comparisons with published academic recommendation systems. The training of the models was done by using two real-world datasets that contain user-to-user and user-to-item information. The results show the system performing with equal efficiency as the sourced academic models, and also highlight the suitability of the system for recommendation tasks.\n",
    "\n",
    "The associated report for this research can be accessed [here](https://drive.google.com/file/d/1rlg-qpLjy5kA0SMW5FDsr1YtZ0OJK90X/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents<a class=\"anchor\" id=\"contents\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "**1** &nbsp;&nbsp;**[Import dependencies](#dw-dep)**<br>\n",
    "\n",
    "**2** &nbsp;&nbsp;**[Download data](#data)**<br>\n",
    "\n",
    "**3** &nbsp;&nbsp;**[Getting interactions](#preprocess-data)**<br>\n",
    "\n",
    "**4** &nbsp;&nbsp;**[Graph Neural Network](#gnn)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.1.&nbsp;&nbsp;*[Multi-Layer Perceptron](#mlp)*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.2.&nbsp;&nbsp;*[Aggregator](#aggregator)*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.3.&nbsp;&nbsp;*[Item modelling](#item-model)*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.4.&nbsp;&nbsp;*[User modelling](#user-model)*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.5.&nbsp;&nbsp;*[Model $X_a$](#model-x)*<br>\n",
    "\n",
    "**5** &nbsp;&nbsp;**[Training](#training)**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.1.&nbsp;&nbsp;*[Preprocess dataset and create graph](#preprocess-dataset)*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.2.&nbsp;&nbsp;*[Hyperparameters and seting up the model](#params)*<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.3.&nbsp;&nbsp;*[Train the model](#train)*<br>\n",
    "\n",
    "**6** &nbsp;&nbsp;**[Testing](#testing)**<br>\n",
    "\n",
    "**7** &nbsp;&nbsp;**[Results](#results)**<br>\n",
    "\n",
    "**8** &nbsp;&nbsp;**[References](#references)**<br>\n",
    "\n",
    "**9** &nbsp;&nbsp;**[Notes](#notes)**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> To return to the contents, press the üîù icon located in the title of each chapter.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1&nbsp;&nbsp;Import dependencies <a class=\"anchor\" id=\"dw-dep\"></a> [üîù](#contents)\n",
    "\n",
    "This section imports the necessary libraries needed to develop the GNN recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note:</b> <li>Please ensure to have the <a href='https://github.com/mughees-asif/postgraduate-research-project/blob/main/collate.py'><code>collate.py</code></a> function in the root folder before running the experiment.</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collate import collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2&nbsp;&nbsp;Download data <a class=\"anchor\" id=\"data\"></a> [üîù](#contents)\n",
    "\n",
    "This section downloads the Ciao and Epinions data sets from the official [GitHub](https://github.com/mughees-asif/) repository of this project. Alternatively, they can also be sourced from [here](https://www.cse.msu.edu/~tangjili/datasetcode/truststudy.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> <li>The following cellblock should only uncommented if the notebook is being run on a <b>Google Colab</b> instance.</li> <li>The command downloads the datasets and sets them up correctly in the Colab environment.</li> <li> If running on a local machine, please disregard the cellblock and ensure to have the <code>data</code> folder (download from above) present in the root folder of the project i.e., <code>~/postgraduate-research-project/data/</code>.</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sF0PfJNVU9pJ",
    "outputId": "3ec5b40c-8b8e-47b0-f828-941465f7032d"
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/mughees-asif/postgraduate-research-project/raw/master/data.zip\n",
    "# !unzip /content/data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViLefaDdRjf8"
   },
   "source": [
    "## 3&nbsp;&nbsp;Getting interactions <a class=\"anchor\" id=\"preprocess-data\"></a> [üîù](#contents)\n",
    "\n",
    "This section will sift through the dataset to establish the interactions between the user-user and user-item categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t8QImMumRjf9"
   },
   "outputs": [],
   "source": [
    "class CreateInteractions(Dataset):\n",
    "    def __init__(self, data, user_item_list, user_user_list, user_user_item_list, item_user_list):\n",
    "        self.data = data\n",
    "        self.u_items_list = user_item_list\n",
    "        self.u_users_list = user_user_list\n",
    "        self.u_users_items_list = user_user_item_list\n",
    "        self.i_users_list = item_user_list\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Baseline parameters\n",
    "        user_id = self.data[index][0]\n",
    "        item_id = self.data[index][1]\n",
    "        label = self.data[index][2]\n",
    "        \n",
    "        # Interaction information\n",
    "        user_item = self.u_items_list[user_id]\n",
    "        user_user = self.u_users_list[user_id]\n",
    "        user_user_item = self.u_users_items_list[user_id]\n",
    "        item_user = self.i_users_list[item_id]\n",
    "\n",
    "        return (user_id, item_id, label), user_item, user_user, user_user_item, item_user\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7FHQ7iyRjf_"
   },
   "source": [
    "## 4&nbsp;&nbsp;Graph Neural Network (GNN)<a class=\"anchor\" id=\"gnn\"></a> [üîù](#contents)\n",
    "\n",
    "A graph $\\mathcal{G}$ is represented by the notation $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$, where $\\mathcal{V}$ is representative of the set of available nodes and $\\mathcal{E}$ is the set of edges. \n",
    "\n",
    "Furthermore, $v_i \\in \\mathcal{V}$ is a node with an edge $e_{ij}=(v_i,v_j) \\in \\mathcal{E}$ extending from $v_j$ to $v_i$, and the local neighbourhood of the node $v$ can be denoted as $\\mathcal{N}(v)=\\{u \\in \\mathcal{V}|(v,u) \\in \\mathcal{E}\\}$.\n",
    "\n",
    "The main intuition behind GNNs is the iterative aggregation (Section 4.2.) of the feature information from a neighbourhood of nodes that is integrated (Section 4.1.) with the information from a current node during the propagation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.&nbsp;&nbsp;Multi-Layer Perceptron (MLP)<a class=\"anchor\" id=\"mlp\"></a>\n",
    "\n",
    "<img src=\"./images/mlp.png\" alt=\"rating\" style=\"width: 500px;\"/>\n",
    "<h5 align=\"center\">Figure 1: Multi-Layer Perceptron</h5>\n",
    "\n",
    "A Multi-Layer Perceptron (MLP) is introduced to concatenate (update) the two vectors (See Figure 1 above), resulting in:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\boldsymbol{\\mathrm{h}}_{i} = \\sigma (W_{l} \\cdot c_{l-1} + b_{i})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, $c_l = \\left[ \\boldsymbol{\\mathrm{h}}_{i}^{I} \\oplus \\boldsymbol{\\mathrm{h}}_{i}^{S} \\right]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        # Seqeuntial container for 2 linear transformation layers with ReLU \n",
    "        # as the activation function\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim//2, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim//2, output_dim, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.&nbsp;&nbsp;Aggregator<a class=\"anchor\" id=\"aggregator\"></a>\n",
    "\n",
    "$$\n",
    "\\mathrm{Aggregation}:\\;\\;\\boldsymbol{\\mathrm{n}}_v = \\mathrm{Aggregator}_l \\left(\\left\\{ \\boldsymbol{\\mathrm{h}}_{u}^{l}, \\forall u \\in \\mathcal{N}_v \\right\\}\\right)\n",
    "$$\n",
    "\n",
    "where, $\\boldsymbol{\\mathrm{h}}_{u}^{l}$ that represents the node at the $l^{th}$ layer and $\\mathcal{N}(v)$ is the neighbourhood of the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0CNFKW9vRjf_"
   },
   "outputs": [],
   "source": [
    "class Aggregator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Aggregator, self).__init__()\n",
    "        # Simple linear `y=mx^T+c` transformation\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.&nbsp;&nbsp;Item modelling<a class=\"anchor\" id=\"item-model\"></a>\n",
    "\n",
    "<img src=\"./images/item-modelling.png\" alt=\"rating\" style=\"width: 400px;\"/>\n",
    "<h5 align=\"center\">Figure 2: Item modelling framework</h5>\n",
    "\n",
    "For each item, the users' preferences are aggregated i.e., the mean of the ratings ranging from $1$ to $5$ for all items $(R = r \\in {1,2,3,4,5})$, and using a MLP, the two vectors holding information regarding plain user embedding $\\boldsymbol{\\mathrm{p}}_{t}$ and opinion embedding $\\boldsymbol{\\mathrm{e}}_{r}$ are used to develop a user representation $\\boldsymbol{\\mathrm{f}}_{jt}$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\boldsymbol{\\mathrm{f}}_{jt} = g_{u} (\\boldsymbol{\\mathrm{p}}_{t} \\oplus \\boldsymbol{\\mathrm{e}}_{r})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The latent factors are derived by the introduction of an attention mechanism:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\boldsymbol{\\mathrm{z}}_{j} = \\sigma \\left( \\boldsymbol{\\mathrm{W}} \\cdot A_{\\mathrm{users}} \\left( {\\boldsymbol{\\mathrm{f}}}_{jt}, \\forall t \\in B(j) \\right) + \\boldsymbol{b}\\right) \\\\\n",
    "    \\\\\n",
    "    \\boldsymbol{\\mathrm{z}}_{j} = \\sigma \\left( \\boldsymbol{\\mathrm{W}} \\cdot \\left\\{ \\sum_{t \\in B(j)}\\mu_{jt}{\\boldsymbol{\\mathrm{f}}}_{jt}\\right\\} + \\boldsymbol{b}\\right)    \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, $\\mu_{jt}$ is \"$\\ldots$ to capture heterogeneous influence from user-item interactions on learning item latent factor\"<sup>1</sup>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Please refer to the mathematical notation to understand the variables.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModelling(nn.Module):\n",
    "    def __init__(self, embedded_dimensions, user_embedding, item_embedding, rating_embedding):\n",
    "        super(ItemModelling, self).__init__()\n",
    "        self.emb_dim = embedded_dimensions\n",
    "        self.user_emb = user_embedding\n",
    "        self.item_emb = item_embedding\n",
    "        self.rating_emb = rating_embedding\n",
    "\n",
    "        self.g_u = MLP(2 * self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.item_users_attn = MLP(2 * self.emb_dim, 1)\n",
    "        self.aggr_users = Aggregator(self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.eps = 1e-10\n",
    "\n",
    "    def forward(self, iids, i_user_pad):\n",
    "        p_t = self.user_emb(i_user_pad[:, :, 0])\n",
    "        i_user_er = self.rating_emb(i_user_pad[:, :, 1])\n",
    "        mask_i = torch.where(i_user_pad[:, :, 0] > 0, torch.tensor([1.], device=self.device),\n",
    "                             torch.tensor([0.], device=self.device))\n",
    "        \n",
    "        f_jt = self.g_u(torch.cat([p_t, i_user_er], dim=2).view(-1, 2 * self.emb_dim)).view(p_t.size())\n",
    "        q_j = mask_i.unsqueeze(2).expand_as(f_jt) * self.item_emb(iids).unsqueeze(1).expand_as(f_jt)\n",
    "        \n",
    "        mu_jt = self.item_users_attn(torch.cat([f_jt, q_j], dim=2).view(-1, 2 * self.emb_dim)).view(mask_i.size())\n",
    "        mu_jt = torch.exp(mu_jt) * mask_i\n",
    "        mu_jt = mu_jt / (torch.sum(mu_jt, 1).unsqueeze(1).expand_as(mu_jt) + self.eps)\n",
    "\n",
    "        z_j = self.aggr_users(torch.sum(mu_jt.unsqueeze(2).expand_as(f_jt) * f_jt, 1))\n",
    "\n",
    "        return z_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.&nbsp;&nbsp;User modelling<a class=\"anchor\" id=\"user-model\"></a>\n",
    "\n",
    "#### Modelling components<sup>2</sup>\n",
    "\n",
    "The user modelling operation aims to learn the latent factors $\\boldsymbol{\\mathrm{h}}_{i} \\in \\mathcal{R}^d$ of users $u_i$.  This operation requires the concatenation of two latent factors to obtain the user latent factors $\\boldsymbol{\\mathrm{h}}_{i}$: item space user latent factor $\\boldsymbol{\\mathrm{h}}_{i}^{I} \\in \\mathcal{R}^d$ from the user-item graph, and a social space user latent factor $\\boldsymbol{\\mathrm{h}}_{i}^{S} \\in \\mathcal{R}^d$ from the social graph.\n",
    "\n",
    "<img src=\"./images/user-modelling-0.png\" alt=\"combo\" style=\"width: 750px;\"/> \n",
    "<h5 align=\"center\">Figure 3: User modelling components</h5>\n",
    "\n",
    "##### Item space\n",
    "\n",
    "The item space operation utilises the interactions between the users and items and also the users' preferences regarding the item, all encoded as a user-item graph. The main premise is to learn item-space user latent factor $\\boldsymbol{\\mathrm{h}}_{i}^{I}$. This can be defined in the classic $y=mx+c$ equivalent linear function as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\boldsymbol{\\mathrm{h}}_{i}^{I} = \\sigma \\left( \\boldsymbol{\\mathrm{W}} \\cdot A_{\\mathrm{item}} \\left( {\\boldsymbol{\\mathrm{x}}}_{ia}, \\forall a \\in C(i) \\right) + \\boldsymbol{b}\\right)\n",
    "    \\label{eq3}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, $\\sigma$ is the rectified linear unit function, $\\boldsymbol{\\mathrm{W}}$ are the weights of the network, $\\boldsymbol{b}$ is the bias, $A_{\\mathrm{item}}$ is the aggregation operation, $C(i)$ are the items the user interacted wit, and $\\boldsymbol{\\mathrm{x}}_{ia}$ is representation vector that includes the users' opinion. \n",
    "\n",
    "The output is the representation vector that includes the users' opinion on a certain item $\\boldsymbol{\\mathrm{x}}_{ia}$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\boldsymbol{\\mathrm{x}}_{ia} = g_{v}\\left( \\boldsymbol{\\mathrm{q}}_a \\oplus \\boldsymbol{\\mathrm{e}}_r \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, $g_v$ is the MLP.\n",
    "\n",
    "A $2$-layer attention mechanism intervenes where each interaction is given an individual weight dependent on the user's interest in the item:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\boldsymbol{\\mathrm{h}}_{i}^{I} = \\sigma \\left( \\boldsymbol{\\mathrm{W}} \\cdot \\left\\{ \\sum_{a \\in C(i)}\\alpha_{ia}{\\boldsymbol{\\mathrm{x}}}_{ia}\\right\\} + \\boldsymbol{b}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, $\\alpha_{ia}$ is representative of the interaction between the user $u_i$ and the item $v_a$. \n",
    "\n",
    "##### Social space\n",
    "\n",
    "Incorporating social space latent factors $\\boldsymbol{\\mathrm{h}}_{i}^{S}$ that are an aggregation of the neighbouring users item space $A_{\\mathrm{neighbours}}(\\cdot)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\boldsymbol{\\mathrm{h}}_{i}^{S} = \\sigma \\left( \\boldsymbol{\\mathrm{W}} \\cdot A_{\\mathrm{neighbours}} \\left( {\\boldsymbol{\\mathrm{h}}}_{o}^{I}, \\forall o \\in N(i) \\right) + \\boldsymbol{b}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "To diminish the impact of assuming that all neighbours contribute equally, an attention mechanism using a $2$-layer neural network is introduced that develops the correlation between user-to-user and user-to-item interaction:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "     \\boldsymbol{\\mathrm{h}}_{i}^{S} = \\sigma \\left( \\boldsymbol{\\mathrm{W}} \\cdot \\left\\{ \\sum_{o \\in N(i)}\\beta_{io}{\\boldsymbol{\\mathrm{h}}}_{o}^{I}\\right\\} + \\boldsymbol{b}\\right)   \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, $\\beta_{io}$ is representative of the interaction between the user's social circle $u_i$ and the item $v_a$. \n",
    "\n",
    "#### Overall operation\n",
    "\n",
    "Using the MLP, the vectors are concatenated.\n",
    "\n",
    "<img src=\"./images/user-modelling.png\" alt=\"rating\" style=\"width: 400px;\"/>\n",
    "<h5 align=\"center\">Figure 4: User modelling overall</h5>\n",
    "\n",
    "#### Variants\n",
    "\n",
    "The variants can be developed as follows:\n",
    "\n",
    "* $X_a$: As described above and coded below (default setting).\n",
    "* $X_b$: To disable the item-space operation, comment out/alter the **relevant lines of code indicted below**. Restart the kernel and run the notebook again to train the GNN.\n",
    "* $X_c$: Same as above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Please refer to the mathematical notation to understand the variables.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModelling(nn.Module):\n",
    "    def __init__(self, embedded_dimensions, user_embedding, item_embedding, rating_embedding):\n",
    "        super(UserModelling, self).__init__()\n",
    "        self.emb_dim = embedded_dimensions\n",
    "        self.user_emb = user_embedding\n",
    "        self.item_emb = item_embedding\n",
    "        self.rating_emb = rating_embedding\n",
    "\n",
    "        self.g_v = MLP(2 * self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.user_item_attn = MLP(2 * self.emb_dim, 1)\n",
    "        self.aggr_items = Aggregator(self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.user_user_attn = MLP(2 * self.emb_dim, 1)\n",
    "        self.aggr_neighbors = Aggregator(self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * self.emb_dim, self.emb_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.emb_dim, self.emb_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.emb_dim, self.emb_dim, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.eps = 1e-10\n",
    "\n",
    "    def forward(self, uids, u_item_pad, u_user_pad, u_user_item_pad):\n",
    "        q_a = self.item_emb(u_item_pad[:, :, 0])\n",
    "        u_item_er = self.rating_emb(u_item_pad[:, :, 1])\n",
    "        x_ia = self.g_v(torch.cat([q_a, u_item_er], dim=2).view(-1, 2 * self.emb_dim)).view(q_a.size())\n",
    "        mask_u = torch.where(u_item_pad[:, :, 0] > 0, torch.tensor([1.], device=self.device),\n",
    "                             torch.tensor([0.], device=self.device))\n",
    "        p_i = mask_u.unsqueeze(2).expand_as(x_ia) * self.user_emb(uids).unsqueeze(1).expand_as(x_ia)\n",
    "        alpha = self.user_item_attn(torch.cat([x_ia, p_i], dim=2).view(-1, 2 * self.emb_dim)).view(mask_u.size())\n",
    "        alpha = torch.exp(alpha) * mask_u\n",
    "        alpha = alpha / (torch.sum(alpha, 1).unsqueeze(1).expand_as(alpha) + self.eps)\n",
    "        ################################################################\n",
    "        # Comment out the line below to disable the item-space operation\n",
    "        ################################################################\n",
    "        h_iI = self.aggr_items(torch.sum(alpha.unsqueeze(2).expand_as(x_ia) * x_ia, 1))\n",
    "        ################################################################\n",
    "\n",
    "        q_a_s = self.item_emb(u_user_item_pad[:, :, :, 0])\n",
    "        u_user_item_er = self.rating_emb(u_user_item_pad[:, :, :, 1])\n",
    "        x_ia_s = self.g_v(torch.cat([q_a_s, u_user_item_er], dim=2).view(-1, 2 * self.emb_dim)).view(q_a_s.size())\n",
    "        mask_s = torch.where(u_user_item_pad[:, :, :, 0] > 0, torch.tensor([1.], device=self.device),\n",
    "                             torch.tensor([0.], device=self.device))\n",
    "        p_i_s = mask_s.unsqueeze(3).expand_as(x_ia_s) * self.user_emb(u_user_pad).unsqueeze(2).expand_as(x_ia_s)\n",
    "        alpha_s = self.user_item_attn(torch.cat([x_ia_s, p_i_s], dim=3).view(-1, 2 * self.emb_dim)).view(mask_s.size())\n",
    "        alpha_s = torch.exp(alpha_s) * mask_s\n",
    "        alpha_s = alpha_s / (torch.sum(alpha_s, 2).unsqueeze(2).expand_as(alpha_s) + self.eps)\n",
    "        h_oI_temp = torch.sum(alpha_s.unsqueeze(3).expand_as(x_ia_s) * x_ia_s, 2)\n",
    "        h_oI = self.aggr_items(h_oI_temp.view(-1, self.emb_dim)).view(h_oI_temp.size())\n",
    "\n",
    "        beta = self.user_user_attn(torch.cat([h_oI, self.user_emb(u_user_pad)], dim=2).view(-1, 2 * self.emb_dim)).view(\n",
    "            u_user_pad.size())\n",
    "        mask_su = torch.where(u_user_pad > 0, torch.tensor([1.], device=self.device),\n",
    "                              torch.tensor([0.], device=self.device))\n",
    "        beta = torch.exp(beta) * mask_su\n",
    "        beta = beta / (torch.sum(beta, 1).unsqueeze(1).expand_as(beta) + self.eps)\n",
    "        ################################################################\n",
    "        # Comment out the line below to disable the social-space operation\n",
    "        ################################################################\n",
    "        h_iS = self.aggr_neighbors(torch.sum(beta.unsqueeze(2).expand_as(h_oI) * h_oI, 1))\n",
    "        ################################################################\n",
    "        \n",
    "        ################################################################\n",
    "        # Uncomment the relevant user latent factor below \n",
    "        ################################################################\n",
    "        # Default: Includes both operations\n",
    "        h_i = self.mlp(torch.cat([h_iI, h_iS], dim=1))\n",
    "        # Item-space operation eliminated\n",
    "        # h_i = self.mlp(h_iS)\n",
    "        # Social-space operation eliminated\n",
    "        # h_i = self.mlp(h_iI)\n",
    "        ################################################################\n",
    "\n",
    "        return h_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.&nbsp;&nbsp;Model $X_a$<a class=\"anchor\" id=\"model-x\"></a>\n",
    "\n",
    "<img src=\"./images/rating.png\" alt=\"rating\" style=\"width: 400px;\"/>\n",
    "<h5 align=\"center\">Figure 5: Model $X$ framework displaying the two main components needed for a rating prediction</h5>\n",
    "\n",
    "The latent factors gained from the previous sections are concatenated, $\\boldsymbol{\\mathrm{h}}_i \\oplus \\boldsymbol{\\mathrm{z}}_j$, and passed through a MLP to get the final ratings $r_{ij}^{'}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNeuralNetwork(nn.Module):\n",
    "    def __init__(self, users, items, ratings, emb_dim=64):\n",
    "        super(GraphNeuralNetwork, self).__init__()\n",
    "        self.n_users = users\n",
    "        self.n_items = items\n",
    "        self.n_ratings = ratings\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.user_emb = nn.Embedding(self.n_users, self.emb_dim, padding_idx=0)\n",
    "        self.item_emb = nn.Embedding(self.n_items, self.emb_dim, padding_idx=0)\n",
    "        self.rating_emb = nn.Embedding(self.n_ratings, self.emb_dim, padding_idx=0)\n",
    "\n",
    "        self.user_model = UserModelling(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n",
    "        self.item_model = ItemModelling(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * self.emb_dim, self.emb_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.emb_dim, self.emb_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.emb_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, uids, iids, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad):\n",
    "        h_i = self.user_model(uids, u_item_pad, u_user_pad, u_user_item_pad)\n",
    "        z_j = self.item_model(iids, i_user_pad)\n",
    "\n",
    "        r_ij = self.mlp(torch.cat([h_i, z_j], dim=1))\n",
    "\n",
    "        return r_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQarCNCvRjgA"
   },
   "source": [
    "## 5&nbsp;&nbsp;Training <a class=\"anchor\" id=\"training\"></a> [üîù](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfNuENP0RjgC"
   },
   "source": [
    "### 5.1.&nbsp;&nbsp;Preprocess dataset and create graph<a class=\"anchor\" id=\"preprocess-dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note:</b> <li>If running on a <b>Google Colab</b> instance, please change the filepaths accordingly:<ul><code>'/content/dataset_epinion.pkl' OR '/content/dataset_ciao.pkl'</code></ul><ul><code>'/content/list_epinions.pkl' OR '/content/list_ciao.pkl'</code></ul></li>\n",
    "    <li>If running on a <b>local machine</b> instance, please change the filepaths accordingly:<ul><code>'./data/dataset_epinion.pkl' OR './data/dataset_ciao.pkl'</code></ul><ul><code>'./data/list_epinions.pkl' OR './data/list_ciao.pkl'</code></ul></li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2o_KviG9RjgC"
   },
   "outputs": [],
   "source": [
    "with open('./data/dataset_epinions.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    validate = pickle.load(f)\n",
    "    test = pickle.load(f)\n",
    "\n",
    "with open('./data/list_epinions.pkl', 'rb') as f:\n",
    "    user_item_list = pickle.load(f)\n",
    "    user_user_list = pickle.load(f)\n",
    "    user_user_item_list = pickle.load(f)\n",
    "    item_user_list = pickle.load(f)\n",
    "    (user_count, item_count, rate_count) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ChoqM7cnRjgD"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data = CreateInteractions(train, user_item_list, user_user_list, user_user_item_list, item_user_list)\n",
    "valid_data = CreateInteractions(validate, user_item_list, user_user_list, user_user_item_list, item_user_list)\n",
    "test_data = CreateInteractions(test, user_item_list, user_user_list, user_user_item_list, item_user_list)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.&nbsp;&nbsp;Hyperparameters and seting up the model<a class=\"anchor\" id=\"params\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphNeuralNetwork(\n",
      "  (user_emb): Embedding(22167, 64, padding_idx=0)\n",
      "  (item_emb): Embedding(296278, 64, padding_idx=0)\n",
      "  (rating_emb): Embedding(28, 64, padding_idx=0)\n",
      "  (user_model): UserModelling(\n",
      "    (user_emb): Embedding(22167, 64, padding_idx=0)\n",
      "    (item_emb): Embedding(296278, 64, padding_idx=0)\n",
      "    (rating_emb): Embedding(28, 64, padding_idx=0)\n",
      "    (g_v): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (user_item_attn): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (aggr_items): Aggregator(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (user_user_attn): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (aggr_neighbors): Aggregator(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (item_model): ItemModelling(\n",
      "    (user_emb): Embedding(22167, 64, padding_idx=0)\n",
      "    (item_emb): Embedding(296278, 64, padding_idx=0)\n",
      "    (rating_emb): Embedding(28, 64, padding_idx=0)\n",
      "    (g_u): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (item_users_attn): MLP(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (aggr_users): Aggregator(\n",
      "      (mlp): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "embed_dim = 64\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 25\n",
    "\n",
    "model = GraphNeuralNetwork(user_count+1, item_count+1, rate_count+1, embed_dim).to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 4, gamma = 0.1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqhnTKi1RjgF"
   },
   "source": [
    "### 5.3.&nbsp;&nbsp;Train the model<a class=\"anchor\" id=\"train\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Note:</b> <li>Ensure there is an empty <code>'/trained_models/'</code> folder in the root directory i.e., <code>'~/postgraduate-research-project/trained_models/'</code>.</li>\n",
    "    <li>This applies to <b>both</b> <code>Google Colab</code> and local machine instances.</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaj75cFoRjgF",
    "outputId": "2be4ae6b-3981-4ae5-f36b-b1a77f4e0b8f"
   },
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    s_loss = 0\n",
    "    for i, (user_id, item_id, labels, user_item, user_user, user_user_item, item_user) in tqdm(enumerate(train_loader),\n",
    "                                                                                               total=len(train_loader)):\n",
    "        user_id = user_id.to(device)\n",
    "        item_id = item_id.to(device)\n",
    "        labels = labels.to(device)\n",
    "        user_item = user_item.to(device)\n",
    "        user_user = user_user.to(device)\n",
    "        user_user_item = user_user_item.to(device)\n",
    "        item_user = item_user.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_id, item_id, user_item, user_user, user_user_item, item_user)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        s_loss += loss_val\n",
    "\n",
    "        iter_num = epoch * len(train_loader) + i + 1\n",
    "\n",
    "    # Validating\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for user_id, item_id, labels, user_item, user_user, user_user_item, item_user in tqdm(valid_loader):\n",
    "            user_id = user_id.to(device)\n",
    "            item_id = item_id.to(device)\n",
    "            labels = labels.to(device)\n",
    "            user_item = user_item.to(device)\n",
    "            user_user = user_user.to(device)\n",
    "            user_user_item = user_user_item.to(device)\n",
    "            item_user = item_user.to(device)\n",
    "            preds = model(user_id, item_id, user_item, user_user, user_user_item, item_user)\n",
    "            error = torch.abs(preds.squeeze(1) - labels)\n",
    "            errors.extend(error.data.cpu().numpy().tolist())\n",
    "\n",
    "    # Evaluation metrics\n",
    "    mae = np.mean(errors)\n",
    "    rmse = np.sqrt(np.mean(np.power(errors, 2)))\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    ckpt_dict = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(ckpt_dict, 'trained_models/latest_checkpoint.pth')\n",
    "\n",
    "    # Save model for testing\n",
    "    best_mae = 0\n",
    "    if epoch == 0:\n",
    "        best_mae = mae\n",
    "    elif mae < best_mae:\n",
    "        best_mae = mae\n",
    "        torch.save(ckpt_dict, 'trained_models/best_checkpoint_{}.pth'.format(embed_dim))\n",
    "\n",
    "    print('Epoch #{}: MAE: {:.4f}, RMSE: {:.4f}, Best MAE: {:.4f}'.format(epoch + 1, mae, rmse, best_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFD-FzMERjgG"
   },
   "source": [
    "## 6&nbsp;&nbsp;Testing <a class=\"anchor\" id=\"testing\"></a> [üîù](#contents)\n",
    "\n",
    "The evaluation criteria included examining two negatively-oriented metrics to analyse the model's precision in measuring the likelihood of a user giving a certain rating for an item, where the lowest numerical value is taken as the most accurate. The metrics serve as an indication of the error in the final rating prediction. Lastly, the training was run for $25$ epochs, and the model with the best metrics was saved at intermittent checkpoints to be used later for testing:\n",
    "\n",
    "* **Mean Absolute Error** (MAE): Measures the average magnitude of the prediction $y_i$ and true $x_i$ errors without any directional considerations on $n$ points:\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathrm{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - x_i|\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* **Root Mean Squared Error** (RMSE): Same as MAE but with the caveat of square-rooting the average of the squared errors which translates into enhanced sensitivity for larger errors:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(|y_i - x_i|\\right)^2}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22savj_zRjgG",
    "outputId": "0855d26c-488b-4d7a-fd5b-da6fef5b4e4d"
   },
   "outputs": [],
   "source": [
    "embed_dim = 64\n",
    "checkpoint = torch.load('trained_models/best_checkpoint_{}.pth'.format(embed_dim))\n",
    "model = GraphNeuralNetwork(user_count+1, item_count+1, rate_count+1, embed_dim).to(device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "test_errors = []\n",
    "with torch.no_grad():\n",
    "    for user_id, item_id, labels, user_item, user_user, user_user_item, item_user in tqdm(test_loader):\n",
    "        user_id = user_id.to(device)\n",
    "        item_id = item_id.to(device)\n",
    "        labels = labels.to(device)\n",
    "        user_item = user_item.to(device)\n",
    "        user_user = user_user.to(device)\n",
    "        user_user_item = user_user_item.to(device)\n",
    "        item_user = item_user.to(device)\n",
    "        predictions = model(user_id, item_id, user_item, user_user, user_user_item, item_user)\n",
    "        error = torch.abs(predictions.squeeze(1) - labels)\n",
    "        test_errors.extend(error.data.cpu().numpy().tolist())\n",
    "\n",
    "test_mae = np.mean(test_errors)\n",
    "test_rmse = np.sqrt(np.mean(np.power(test_errors, 2)))\n",
    "print('Test: MAE: {:.4f}, RMSE: {:.4f}'.format(test_mae, test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c9Pxa8xRjgH"
   },
   "source": [
    "## 7&nbsp;&nbsp;Results <a class=\"anchor\" id=\"results\"></a> [üîù](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The framework with the associated variants was benchmarked against published recommendation systems from academic literature, where the results were averaged to enable comparison. \n",
    "\n",
    "##### The links in the references below will take the reader to the implementations that were used for this research.\n",
    "\n",
    "* **SoRec**: Ma, H., Yang, H., Lyu, M.R. and King, I., 2008, October. [SoRec: Social Recommendation using Probabilistic Matrix Factorisation.](https://github.com/SeizeTheMoment/SoRec-Social-Recommendation-Using-Probabilistic-Matrix-Factorization) _In Proceedings of the 17th ACM Conference on Information and Knowledge anagement_ (pp. 931-940).\n",
    "\n",
    "* **SoReg**: Ma, H., Zhou, D., Liu, C., Lyu, M.R. and King, I., 2011, February. [Recommender Systems with Social Regularization.](https://github.com/Coder-Yu/QRec) _In Proceedings of the fourth ACM International Conference on Web Search and Data Mining_ (pp. 287-296).\n",
    "\n",
    "* **DeepSoR**: Fan, W., Li, Q. and Cheng, M., 2018, April. [Deep Modelling of Social Relations for Recommendation.](https://github.com/wenqifan03/GraphRec-WWW19) _In Proceedings of the AAAI Conference on Artificial Intelligence_ (Vol. 32, No. 1).\n",
    "\n",
    "* **GC-MC**: Berg, R.V.D., Kipf, T.N. and Welling, M., 2017. [Graph Convolutional Matrix Completion.](https://github.com/riannevdberg/gc-mc) _arXiv preprint_ arXiv:1706.02263.\n",
    "\n",
    "### Evaluation metrics for all the models\n",
    "\n",
    "|  Dataset | Metric | Algorithm |       |         |         |       |         |         |\n",
    "|:--------:|:------:|:---------:|:-----:|:-------:|:-------:|:-----:|:-------:|:-------:|\n",
    "|          |        |   **SoRec**   | **SoReg** | **DeepSoR** | **GCMC+SN** | $\\boldsymbol{X_a}$    | $\\boldsymbol{X_b}$ | $\\boldsymbol{X_c}$ |\n",
    "|   **Ciao**   | _MAE_    | $0.87$      | $0.85$  | $0.82$    | $0.81$    |$0.73$          | $0.79$       | $0.88$       |\n",
    "|          | _RMSE_   | $1.04$      | $1.06$  | $1.03$    | $1.02$    | $1.00$          | $0.98$       | $1.01$       |\n",
    "| **Epinions** | _MAE_    | $1.09$      | $1.07$  | $0.89$    | $1.01$    |$1.01$          | $1.04$       | $1.02$       |\n",
    "|          | _RMSE_   | $1.14$      | $1.17$  | $1.09$    | $1.07$    | $0.87$          | $1.02$       | $0.99$     |\n",
    "\n",
    "<img src=\"./images/mae.png\" alt=\"mae\" style=\"width: 500px;\"/>\n",
    "<h5 align=\"center\">Figure 6: MAE for both datasets</h5>\n",
    "\n",
    "<img src=\"./images/rmse.png\" alt=\"rmse\" style=\"width: 500px;\"/>\n",
    "<h5 align=\"center\">Figure 7: RMSE for both datasets</h5>\n",
    "\n",
    "### Weighted averages\n",
    "\n",
    "| Algorithm | Dataset |          |\n",
    "|:---------:|:-------:|:--------:|\n",
    "|           |   **Ciao**  | **Epinions** |\n",
    "|   **SoRec**   |  $0.925$  |   $1.115$  |\n",
    "|   **SoReg**   |  $0.950$  |   $1.120$  |\n",
    "|  **DeepSoR**  |  $0.985$  |   $1.000$  |\n",
    "|   **GC-MC**   |  $0.945$  |   $1.040$ |\n",
    "|    $\\boldsymbol{X_a}$    |  $0.885$  |   $0.980$  |\n",
    "|    $\\boldsymbol{X_b}$   |  $0.940$  |   $1.000$  |\n",
    "|    $\\boldsymbol{X_c}$    |  $0.945$  |   $0.945$  |\n",
    "\n",
    "<img src=\"./images/average.png\" alt=\"rating\" style=\"width: 500px;\"/>\n",
    "<h5 align=\"center\">Figure 8: Averaged metrics for all the tested models</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8&nbsp;&nbsp;References <a class=\"anchor\" id=\"references\"></a> [üîù](#contents)\n",
    "\n",
    "<sup>1</sup>Wu, S., Sun, F., Zhang, W., Xie, X. and Cui, B., 2020. Graph Neural Networks in Recommender Systems: A Survey. <i>ACM Computing Surveys</i> (CSUR).<br/>\n",
    "<sup>2</sup>Fan, W., Ma, Y., Li, Q., He, Y., Zhao, E., Tang, J. and Yin, D., 2019, May. Graph Neural Networks for Social Recommendation. <i>In The World Wide Web Conference</i> (pp. 417-426)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9&nbsp;&nbsp;Notes <a class=\"anchor\" id=\"notes\"></a> [üîù](#contents)\n",
    "\n",
    "* This project was developed for the [MSc. Artificial Intelligence](https://www.qmul.ac.uk/postgraduate/taught/coursefinder/courses/artificial-intelligence-msc/) programme as a dissertation project at Queen Mary, University of London. \n",
    "\n",
    "* The motivation for this project aligns with the author's life ambition and interest in modelling relationships found in the Criminal Justice System (CJS) of the U.K. using a 21st-century technological perspective.  Contributing factors include prisoner recidivism and associated influences, and leveraging big data to analyse the bias in the foundational triumvirate of law: judge-lawyer-defendant. Please review the [Lammy Report](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/643001/lammy-review-final-report.pdf) to read about missing state intervention in the rising recidivism rate.\n",
    "\n",
    "* To cite, please use the following information:\n",
    "\n",
    "_BibTeX_:\n",
    "\n",
    "`@misc{asif_nanjangud_2022,`<br />\n",
    "‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ`title = {Recommendation System using Graph Neural Networks},`<br />\n",
    "‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ`url = {https://github.com/mughees-asif/postgraduate-research-project},`<br />\n",
    "‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ`journal = {GitHub},`<br />\n",
    "‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ`publisher = {Mughees Asif},`<br />\n",
    "‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ`author = {Asif, Mughees and Nanjangud, Angadh},`<br />\n",
    "‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ`year = {2022},`<br />\n",
    "‚ÄÉ‚ÄÉ‚ÄÉ‚ÄÉ`month = {Aug}`<br />\n",
    "‚ÄÉ‚ÄÉ‚ÄÉ`}`\n",
    "\n",
    "_Harvard_:\n",
    "\n",
    "`Asif, M., and Nanjangud, A.. (2022). Recommendation System using Graph Neural Networks.`\n",
    "\n",
    "_APA_:\n",
    "\n",
    "`Asif, M., & Nanjangud, A.. (2022). Recommendation System using Graph Neural Networks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:purple'><center><a href='#contents'>üîù</a>&#8592;&#8592;&#8592;&#8592; END &#8594;&#8594;&#8594;&#8594;<a href='#contents'>üîù</a></center></h1>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "interpreter": {
   "hash": "ec7d137c6e0bfe5aec1849c5c512dd0bf44cf2eb2fae9fc2de49724729b3d6c6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
